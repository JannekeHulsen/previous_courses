{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c04e2a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.transforms import *\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1bd677ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 50000\n",
    "VALIDATION_SIZE = 10000\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "\n",
    "LEARNING_RATE = 0.0008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5c48e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize([28, 28]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a6d4d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(root = \"../data/mnist-varres/train/\",\n",
    "                                          transform=transform)\n",
    "\n",
    "train_set, validation_set = torch.utils.data.random_split(dataset, [TRAIN_SIZE, VALIDATION_SIZE])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           num_workers = 2)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set,\n",
    "                                                batch_size = BATCH_SIZE,\n",
    "                                                shuffle = True,\n",
    "                                                num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "78223a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torchvision.datasets.ImageFolder(root = \"../data/mnist-varres/test/\",\n",
    "                                          transform=transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          shuffle = True,\n",
    "                                          num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ce1b5334",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "836cdcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1) # size: batch, 1, 28, 28\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size = 3, stride = 1, padding = 1) # (batch, 16, 14, 14)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1) # (batch, 32, 7, 7)\n",
    "        self.fc1 = nn.Linear(64*3*3, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2) # (batch, 16, 28, 28) # TODO klopt het dat relu en maxpool zijn omgedraaid?\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # (batch, 32, 14, 14)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 2) # (batch, 64, 7, 7)\n",
    "        x = torch.flatten(x, 1) # (batch, 64, 3, 3)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a117004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.Adam(network.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5fd3cf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "val_losses = []\n",
    "val_counter = [i*TRAIN_SIZE for i in range(EPOCHS + 1)]\n",
    "val_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "27463439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Make sure to have \"results\" directory in \"CNN/\"\n",
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            torch.save(network.state_dict(), '../results/model_Q8.pth')\n",
    "            torch.save(optimizer.state_dict(), '../results/optimizer_Q8.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b11ebca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in validation_loader:\n",
    "            output = network(data)\n",
    "            val_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        val_loss /= VALIDATION_SIZE\n",
    "        val_losses.append(val_loss)\n",
    "        val_acc.append(float(100. * correct / VALIDATION_SIZE))\n",
    "        print('\\nValidation set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            val_loss, correct, VALIDATION_SIZE,\n",
    "            100. * correct / VALIDATION_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89a1404",
   "metadata": {},
   "source": [
    "# Training and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fcdcc2f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.312194\n",
      "Train Epoch: 1 [1600/50000 (3%)]\tLoss: 1.845459\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 1.091698\n",
      "Train Epoch: 1 [4800/50000 (10%)]\tLoss: 0.747624\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.180781\n",
      "Train Epoch: 1 [8000/50000 (16%)]\tLoss: 0.848353\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 1.051423\n",
      "Train Epoch: 1 [11200/50000 (22%)]\tLoss: 0.472286\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 0.268537\n",
      "Train Epoch: 1 [14400/50000 (29%)]\tLoss: 0.402681\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 0.421293\n",
      "Train Epoch: 1 [17600/50000 (35%)]\tLoss: 0.192027\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 0.534002\n",
      "Train Epoch: 1 [20800/50000 (42%)]\tLoss: 0.919927\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 0.164797\n",
      "Train Epoch: 1 [24000/50000 (48%)]\tLoss: 0.229819\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.108050\n",
      "Train Epoch: 1 [27200/50000 (54%)]\tLoss: 0.222339\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 0.550889\n",
      "Train Epoch: 1 [30400/50000 (61%)]\tLoss: 0.090447\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 0.417665\n",
      "Train Epoch: 1 [33600/50000 (67%)]\tLoss: 0.138544\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 0.180687\n",
      "Train Epoch: 1 [36800/50000 (74%)]\tLoss: 0.223166\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 0.499260\n",
      "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 0.512185\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 0.397932\n",
      "Train Epoch: 1 [43200/50000 (86%)]\tLoss: 0.260380\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 0.059196\n",
      "Train Epoch: 1 [46400/50000 (93%)]\tLoss: 0.371536\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 0.359722\n",
      "Train Epoch: 1 [49600/50000 (99%)]\tLoss: 0.206639\n",
      "\n",
      "Validation set: Avg. loss: 0.2215, Accuracy: 9323/10000 (93%)\n",
      "\n",
      "EPOCH: 2\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.148284\n",
      "Train Epoch: 2 [1600/50000 (3%)]\tLoss: 0.111084\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 0.237596\n",
      "Train Epoch: 2 [4800/50000 (10%)]\tLoss: 0.324901\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 0.052681\n",
      "Train Epoch: 2 [8000/50000 (16%)]\tLoss: 0.214648\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 0.060032\n",
      "Train Epoch: 2 [11200/50000 (22%)]\tLoss: 0.142994\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.257347\n",
      "Train Epoch: 2 [14400/50000 (29%)]\tLoss: 0.182102\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 0.350997\n",
      "Train Epoch: 2 [17600/50000 (35%)]\tLoss: 0.120626\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.148988\n",
      "Train Epoch: 2 [20800/50000 (42%)]\tLoss: 0.305002\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 0.016587\n",
      "Train Epoch: 2 [24000/50000 (48%)]\tLoss: 0.161726\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.176175\n",
      "Train Epoch: 2 [27200/50000 (54%)]\tLoss: 0.090208\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 0.118766\n",
      "Train Epoch: 2 [30400/50000 (61%)]\tLoss: 0.055154\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.048510\n",
      "Train Epoch: 2 [33600/50000 (67%)]\tLoss: 0.204176\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 0.110991\n",
      "Train Epoch: 2 [36800/50000 (74%)]\tLoss: 0.075250\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.121334\n",
      "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 0.011218\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 0.019906\n",
      "Train Epoch: 2 [43200/50000 (86%)]\tLoss: 0.084155\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.088534\n",
      "Train Epoch: 2 [46400/50000 (93%)]\tLoss: 0.419707\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.667933\n",
      "Train Epoch: 2 [49600/50000 (99%)]\tLoss: 0.158728\n",
      "\n",
      "Validation set: Avg. loss: 0.1379, Accuracy: 9586/10000 (96%)\n",
      "\n",
      "EPOCH: 3\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.329976\n",
      "Train Epoch: 3 [1600/50000 (3%)]\tLoss: 0.101555\n",
      "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 0.150067\n",
      "Train Epoch: 3 [4800/50000 (10%)]\tLoss: 0.013901\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.058236\n",
      "Train Epoch: 3 [8000/50000 (16%)]\tLoss: 0.057842\n",
      "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 0.058667\n",
      "Train Epoch: 3 [11200/50000 (22%)]\tLoss: 0.164937\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.334621\n",
      "Train Epoch: 3 [14400/50000 (29%)]\tLoss: 0.131598\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.087510\n",
      "Train Epoch: 3 [17600/50000 (35%)]\tLoss: 0.004860\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.013043\n",
      "Train Epoch: 3 [20800/50000 (42%)]\tLoss: 0.033541\n",
      "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 0.026179\n",
      "Train Epoch: 3 [24000/50000 (48%)]\tLoss: 0.111334\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.016953\n",
      "Train Epoch: 3 [27200/50000 (54%)]\tLoss: 0.259133\n",
      "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 0.111548\n",
      "Train Epoch: 3 [30400/50000 (61%)]\tLoss: 0.053259\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.032489\n",
      "Train Epoch: 3 [33600/50000 (67%)]\tLoss: 0.006400\n",
      "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 0.292697\n",
      "Train Epoch: 3 [36800/50000 (74%)]\tLoss: 0.021030\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.015246\n",
      "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 0.187591\n",
      "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 0.020513\n",
      "Train Epoch: 3 [43200/50000 (86%)]\tLoss: 0.043651\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 0.010194\n",
      "Train Epoch: 3 [46400/50000 (93%)]\tLoss: 0.005761\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 0.193411\n",
      "Train Epoch: 3 [49600/50000 (99%)]\tLoss: 0.010499\n",
      "\n",
      "Validation set: Avg. loss: 0.1334, Accuracy: 9596/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f'EPOCH: {epoch}')\n",
    "    train(epoch)\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1c6349c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store values\n",
    "np.savetxt(\"../results/training_stats_Q17fixed.csv\", [p for p in zip(train_counter, train_losses)], delimiter=',', fmt='%s')\n",
    "np.savetxt(\"../results/validation_stats_Q17fixed.csv\", [p for p in zip(val_losses, val_acc)], delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0722ec84",
   "metadata": {},
   "source": [
    "# Performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b25c62e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jannekehulsen/miniconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3030, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.295086\n",
      "Train Epoch: 1 [1600/50000 (3%)]\tLoss: 2.030319\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 1.244026\n",
      "Train Epoch: 1 [4800/50000 (10%)]\tLoss: 1.067634\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 0.952617\n",
      "Train Epoch: 1 [8000/50000 (16%)]\tLoss: 0.579303\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 0.488854\n",
      "Train Epoch: 1 [11200/50000 (22%)]\tLoss: 0.791562\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 0.351586\n",
      "Train Epoch: 1 [14400/50000 (29%)]\tLoss: 0.549284\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 0.345628\n",
      "Train Epoch: 1 [17600/50000 (35%)]\tLoss: 0.133538\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 0.639107\n",
      "Train Epoch: 1 [20800/50000 (42%)]\tLoss: 0.137807\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 0.218945\n",
      "Train Epoch: 1 [24000/50000 (48%)]\tLoss: 0.195649\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.680345\n",
      "Train Epoch: 1 [27200/50000 (54%)]\tLoss: 0.480136\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 0.292999\n",
      "Train Epoch: 1 [30400/50000 (61%)]\tLoss: 0.108065\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 0.618784\n",
      "Train Epoch: 1 [33600/50000 (67%)]\tLoss: 0.349973\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 0.175167\n",
      "Train Epoch: 1 [36800/50000 (74%)]\tLoss: 0.347501\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 0.324327\n",
      "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 0.218733\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 0.138877\n",
      "Train Epoch: 1 [43200/50000 (86%)]\tLoss: 0.179579\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 0.150424\n",
      "Train Epoch: 1 [46400/50000 (93%)]\tLoss: 0.276544\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 0.126129\n",
      "Train Epoch: 1 [49600/50000 (99%)]\tLoss: 0.197525\n",
      "\n",
      "Test set: Avg. loss: 0.2436, Accuracy: 9279/10000 (93%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.078331\n",
      "Train Epoch: 2 [1600/50000 (3%)]\tLoss: 0.312351\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 0.229042\n",
      "Train Epoch: 2 [4800/50000 (10%)]\tLoss: 0.108992\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 0.157308\n",
      "Train Epoch: 2 [8000/50000 (16%)]\tLoss: 0.293443\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 0.098697\n",
      "Train Epoch: 2 [11200/50000 (22%)]\tLoss: 0.037393\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.195997\n",
      "Train Epoch: 2 [14400/50000 (29%)]\tLoss: 0.111797\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 0.161708\n",
      "Train Epoch: 2 [17600/50000 (35%)]\tLoss: 0.032760\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.100089\n",
      "Train Epoch: 2 [20800/50000 (42%)]\tLoss: 0.028509\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 0.083586\n",
      "Train Epoch: 2 [24000/50000 (48%)]\tLoss: 0.194017\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.157966\n",
      "Train Epoch: 2 [27200/50000 (54%)]\tLoss: 0.100069\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 0.191366\n",
      "Train Epoch: 2 [30400/50000 (61%)]\tLoss: 0.087686\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.083764\n",
      "Train Epoch: 2 [33600/50000 (67%)]\tLoss: 0.095849\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 0.103081\n",
      "Train Epoch: 2 [36800/50000 (74%)]\tLoss: 0.390482\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.153767\n",
      "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 0.234980\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 0.167370\n",
      "Train Epoch: 2 [43200/50000 (86%)]\tLoss: 0.260808\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.146705\n",
      "Train Epoch: 2 [46400/50000 (93%)]\tLoss: 0.062259\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.245573\n",
      "Train Epoch: 2 [49600/50000 (99%)]\tLoss: 0.046528\n",
      "\n",
      "Test set: Avg. loss: 0.1382, Accuracy: 9604/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.143896\n",
      "Train Epoch: 3 [1600/50000 (3%)]\tLoss: 0.185670\n",
      "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 0.008830\n",
      "Train Epoch: 3 [4800/50000 (10%)]\tLoss: 0.171582\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.003333\n",
      "Train Epoch: 3 [8000/50000 (16%)]\tLoss: 0.115444\n",
      "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 0.282222\n",
      "Train Epoch: 3 [11200/50000 (22%)]\tLoss: 0.118088\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.073671\n",
      "Train Epoch: 3 [14400/50000 (29%)]\tLoss: 0.026819\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.001636\n",
      "Train Epoch: 3 [17600/50000 (35%)]\tLoss: 0.171616\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.022452\n",
      "Train Epoch: 3 [20800/50000 (42%)]\tLoss: 0.119402\n",
      "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 0.120671\n",
      "Train Epoch: 3 [24000/50000 (48%)]\tLoss: 0.090720\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.016832\n",
      "Train Epoch: 3 [27200/50000 (54%)]\tLoss: 0.198658\n",
      "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 0.013766\n",
      "Train Epoch: 3 [30400/50000 (61%)]\tLoss: 0.108950\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.083422\n",
      "Train Epoch: 3 [33600/50000 (67%)]\tLoss: 0.070180\n",
      "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 0.145675\n",
      "Train Epoch: 3 [36800/50000 (74%)]\tLoss: 0.008840\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.139169\n",
      "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 0.041209\n",
      "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 0.108453\n",
      "Train Epoch: 3 [43200/50000 (86%)]\tLoss: 0.057955\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 0.196847\n",
      "Train Epoch: 3 [46400/50000 (93%)]\tLoss: 0.005065\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 0.268997\n",
      "Train Epoch: 3 [49600/50000 (99%)]\tLoss: 0.073481\n",
      "\n",
      "Test set: Avg. loss: 0.1557, Accuracy: 9525/10000 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_set_performance(test_loader, TEST_SIZE): \n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        test_loss /= TEST_SIZE\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, TEST_SIZE,\n",
    "            100. * correct / TEST_SIZE))\n",
    "    return test_loss, float(100 * correct / TEST_SIZE)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3f42c0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1087, Accuracy: 9649/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_SIZE = 10000\n",
    "final_test_avgloss, final_test_acc = test_set_performance(test_loader, TEST_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0459a3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy =  96.48999786376953 %\n",
      "Final Avg. Loss =  0.10866481845663511\n"
     ]
    }
   ],
   "source": [
    "print('Final Test Accuracy = ', final_test_acc, '%')\n",
    "print('Final Avg. Loss = ', final_test_avgloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "51b8aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store values\n",
    "np.savetxt(\"../results/test_stats_Q17fixed.csv\", [(final_test_avgloss, final_test_acc)], delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7d1af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Store values\u001b[39;00m\n\u001b[1;32m      2\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../results/training_stats_Q17fixed.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(train_counter, train_losses)], delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../results/validation_stats_Q17fixed.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(val_losses, \u001b[43mval_acc\u001b[49m)], delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_acc' is not defined"
     ]
    }
   ],
   "source": [
    "# Store values\n",
    "np.savetxt(\"../results/training_stats_Q17fixed.csv\", [p for p in zip(train_counter, train_losses)], delimiter=',', fmt='%s')\n",
    "np.savetxt(\"../results/validation_stats_Q17fixed.csv\", [p for p in zip(val_losses, val_acc)], delimiter=',', fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
