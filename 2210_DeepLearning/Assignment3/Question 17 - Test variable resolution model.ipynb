{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "70fd709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code for Q15 model\n",
    "# Improve saving data\n",
    "# Adjust hyperparameters\n",
    "# Create figure (in R)\n",
    "# Test with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f089219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.transforms import *\n",
    "# from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0bbbba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 0.0013\n",
    "BATCH_INTERVAL = 100\n",
    "TRAIN_SIZE = 50000\n",
    "VALIDATION_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0d188a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "def get_dataloader(train_set, BATCH_SIZE):\n",
    "    return torch.utils.data.DataLoader(train_set, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cda022",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "605fd037",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_32 = torchvision.datasets.ImageFolder(root = '../data/mnist-varres/32/train',\n",
    "                                              transform=transform)\n",
    "train_48 = torchvision.datasets.ImageFolder(root = '../data/mnist-varres/48/train',\n",
    "                                              transform=transform)\n",
    "train_64 = torchvision.datasets.ImageFolder(root = '../data/mnist-varres/64/train',\n",
    "                                              transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9266236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_32, validation_32 = torch.utils.data.random_split(train_32, [math.floor(TRAIN_SIZE/(TRAIN_SIZE+VALIDATION_SIZE)*len(train_32)),\n",
    "                                                                   math.ceil((1-TRAIN_SIZE/(TRAIN_SIZE+VALIDATION_SIZE))*len(train_32))])\n",
    "train_48, validation_48 = torch.utils.data.random_split(train_48, [math.floor(TRAIN_SIZE/(TRAIN_SIZE+VALIDATION_SIZE)*len(train_48)),\n",
    "                                                                    math.ceil((1-TRAIN_SIZE/(TRAIN_SIZE+VALIDATION_SIZE))*len(train_48))])\n",
    "train_64, validation_64 = torch.utils.data.random_split(train_64, [math.floor(TRAIN_SIZE/(TRAIN_SIZE+VALIDATION_SIZE)*len(train_64)),\n",
    "                                                                   math.ceil((1-TRAIN_SIZE/(TRAIN_SIZE+VALIDATION_SIZE))*len(train_64))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ad74b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_32 = get_dataloader(train_32, BATCH_SIZE)\n",
    "train_loader_48 = get_dataloader(train_48, BATCH_SIZE)\n",
    "train_loader_64 = get_dataloader(train_64, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "30ffd7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_loader_32 = get_dataloader(validation_32, BATCH_SIZE)\n",
    "validation_loader_48 = get_dataloader(validation_48, BATCH_SIZE)\n",
    "validation_loader_64 = get_dataloader(validation_64, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deccdc38",
   "metadata": {},
   "source": [
    "# Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "39ec15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        N = 81\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1)  # size: batch, 1, 32, 32\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size = 3, stride = 1, padding = 1) # (batch, 16, 16, 16)\n",
    "        self.conv3 = nn.Conv2d(32, N, kernel_size = 3, stride = 1, padding = 1) # (batch, 32, 8, 8)\n",
    "        self.fc1 = nn.Linear(N, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2) # (batch, 16, 28, 28)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # (batch, 32, 14, 14)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 2) # (batch, N, 8, 8)\n",
    "        x = F.max_pool2d(x, kernel_size = x.size()[2:]) # (batch, N, 4, 4)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "043b1848",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.Adam(network.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "277c4e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "val_losses = []\n",
    "val_counter = [i*TRAIN_SIZE for i in range(EPOCHS + 1)]\n",
    "val_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "80fd2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, train_loader):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = network(data)\n",
    "        \n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % BATCH_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            torch.save(network.state_dict(), '../results/model_Q17variable.pth')\n",
    "            torch.save(optimizer.state_dict(), '../results/optimizer_Q17variable.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f2921428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(validation_loader, VALIDATION_SIZE):\n",
    "    network.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in validation_loader:\n",
    "            output = network(data)\n",
    "            val_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        val_loss /= VALIDATION_SIZE\n",
    "        val_losses.append(val_loss)\n",
    "        val_acc.append(float(100. * correct / VALIDATION_SIZE))\n",
    "        print('\\nValidation set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            val_loss, correct, VALIDATION_SIZE,\n",
    "            100. * correct / VALIDATION_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721f6ffc",
   "metadata": {},
   "source": [
    "# Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "78ed7aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "\tRESOLUTION: 32\n",
      "Train Epoch: 1 [0/16594 (0%)]\tLoss: 2.321974\n",
      "Train Epoch: 1 [3200/16594 (19%)]\tLoss: 1.874787\n",
      "Train Epoch: 1 [6400/16594 (39%)]\tLoss: 1.072306\n",
      "Train Epoch: 1 [9600/16594 (58%)]\tLoss: 0.380115\n",
      "Train Epoch: 1 [12800/16594 (77%)]\tLoss: 0.560354\n",
      "Train Epoch: 1 [16000/16594 (96%)]\tLoss: 0.533825\n",
      "\n",
      "Validation set: Avg. loss: 0.5324, Accuracy: 2778/3319 (84%)\n",
      "\n",
      "\tRESOLUTION: 48\n",
      "Train Epoch: 1 [0/16733 (0%)]\tLoss: 0.859010\n",
      "Train Epoch: 1 [3200/16733 (19%)]\tLoss: 0.534421\n",
      "Train Epoch: 1 [6400/16733 (38%)]\tLoss: 0.552761\n",
      "Train Epoch: 1 [9600/16733 (57%)]\tLoss: 0.321906\n",
      "Train Epoch: 1 [12800/16733 (76%)]\tLoss: 0.320573\n",
      "Train Epoch: 1 [16000/16733 (96%)]\tLoss: 0.392217\n",
      "\n",
      "Validation set: Avg. loss: 0.3465, Accuracy: 2985/3347 (89%)\n",
      "\n",
      "\tRESOLUTION: 64\n",
      "Train Epoch: 1 [0/16672 (0%)]\tLoss: 0.594869\n",
      "Train Epoch: 1 [3200/16672 (19%)]\tLoss: 0.343624\n",
      "Train Epoch: 1 [6400/16672 (38%)]\tLoss: 0.201801\n",
      "Train Epoch: 1 [9600/16672 (58%)]\tLoss: 0.183525\n",
      "Train Epoch: 1 [12800/16672 (77%)]\tLoss: 0.488496\n",
      "Train Epoch: 1 [16000/16672 (96%)]\tLoss: 0.328464\n",
      "\n",
      "Validation set: Avg. loss: 0.2976, Accuracy: 3027/3335 (91%)\n",
      "\n",
      "EPOCH: 2\n",
      "\tRESOLUTION: 32\n",
      "Train Epoch: 2 [0/16594 (0%)]\tLoss: 0.159951\n",
      "Train Epoch: 2 [3200/16594 (19%)]\tLoss: 0.501079\n",
      "Train Epoch: 2 [6400/16594 (39%)]\tLoss: 0.261603\n",
      "Train Epoch: 2 [9600/16594 (58%)]\tLoss: 0.255154\n",
      "Train Epoch: 2 [12800/16594 (77%)]\tLoss: 0.224823\n",
      "Train Epoch: 2 [16000/16594 (96%)]\tLoss: 0.137009\n",
      "\n",
      "Validation set: Avg. loss: 0.2008, Accuracy: 3119/3319 (94%)\n",
      "\n",
      "\tRESOLUTION: 48\n",
      "Train Epoch: 2 [0/16733 (0%)]\tLoss: 0.179261\n",
      "Train Epoch: 2 [3200/16733 (19%)]\tLoss: 0.118804\n",
      "Train Epoch: 2 [6400/16733 (38%)]\tLoss: 0.183598\n",
      "Train Epoch: 2 [9600/16733 (57%)]\tLoss: 0.518268\n",
      "Train Epoch: 2 [12800/16733 (76%)]\tLoss: 0.206554\n",
      "Train Epoch: 2 [16000/16733 (96%)]\tLoss: 0.279386\n",
      "\n",
      "Validation set: Avg. loss: 0.2078, Accuracy: 3122/3347 (93%)\n",
      "\n",
      "\tRESOLUTION: 64\n",
      "Train Epoch: 2 [0/16672 (0%)]\tLoss: 0.063293\n",
      "Train Epoch: 2 [3200/16672 (19%)]\tLoss: 0.179793\n",
      "Train Epoch: 2 [6400/16672 (38%)]\tLoss: 0.662102\n",
      "Train Epoch: 2 [9600/16672 (58%)]\tLoss: 0.208669\n",
      "Train Epoch: 2 [12800/16672 (77%)]\tLoss: 0.201265\n",
      "Train Epoch: 2 [16000/16672 (96%)]\tLoss: 0.423722\n",
      "\n",
      "Validation set: Avg. loss: 0.2001, Accuracy: 3127/3335 (94%)\n",
      "\n",
      "EPOCH: 3\n",
      "\tRESOLUTION: 32\n",
      "Train Epoch: 3 [0/16594 (0%)]\tLoss: 0.120268\n",
      "Train Epoch: 3 [3200/16594 (19%)]\tLoss: 0.031968\n",
      "Train Epoch: 3 [6400/16594 (39%)]\tLoss: 0.164788\n",
      "Train Epoch: 3 [9600/16594 (58%)]\tLoss: 0.043108\n",
      "Train Epoch: 3 [12800/16594 (77%)]\tLoss: 0.241837\n",
      "Train Epoch: 3 [16000/16594 (96%)]\tLoss: 0.097306\n",
      "\n",
      "Validation set: Avg. loss: 0.1594, Accuracy: 3151/3319 (95%)\n",
      "\n",
      "\tRESOLUTION: 48\n",
      "Train Epoch: 3 [0/16733 (0%)]\tLoss: 0.076812\n",
      "Train Epoch: 3 [3200/16733 (19%)]\tLoss: 0.093561\n",
      "Train Epoch: 3 [6400/16733 (38%)]\tLoss: 0.079263\n",
      "Train Epoch: 3 [9600/16733 (57%)]\tLoss: 0.082368\n",
      "Train Epoch: 3 [12800/16733 (76%)]\tLoss: 0.044680\n",
      "Train Epoch: 3 [16000/16733 (96%)]\tLoss: 0.029327\n",
      "\n",
      "Validation set: Avg. loss: 0.1389, Accuracy: 3202/3347 (96%)\n",
      "\n",
      "\tRESOLUTION: 64\n",
      "Train Epoch: 3 [0/16672 (0%)]\tLoss: 0.061343\n",
      "Train Epoch: 3 [3200/16672 (19%)]\tLoss: 0.032559\n",
      "Train Epoch: 3 [6400/16672 (38%)]\tLoss: 0.108451\n",
      "Train Epoch: 3 [9600/16672 (58%)]\tLoss: 0.310440\n",
      "Train Epoch: 3 [12800/16672 (77%)]\tLoss: 0.097307\n",
      "Train Epoch: 3 [16000/16672 (96%)]\tLoss: 0.211957\n",
      "\n",
      "Validation set: Avg. loss: 0.1713, Accuracy: 3151/3335 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loaders = {'32': train_loader_32,\n",
    "                 '48': train_loader_48,\n",
    "                 '64': train_loader_64\n",
    "                }\n",
    "validation_loaders = {'32': validation_loader_32,\n",
    "                      '48': validation_loader_48,\n",
    "                      '64': validation_loader_64\n",
    "                     }\n",
    "\n",
    "validation_size = {'32': len(validation_32),\n",
    "                   '48': len(validation_48),\n",
    "                   '64': len(validation_64)}\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f'EPOCH: {epoch}')\n",
    "    for r in train_loaders.keys():\n",
    "        print(f'\\tRESOLUTION: {r}')\n",
    "        train(epoch, train_loaders[r])\n",
    "        test(validation_loaders[r], validation_size[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd77afab",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e573eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store values\n",
    "np.savetxt(\"../results/training_stats_Q17variable.csv\", [p for p in zip(train_counter, train_losses)], delimiter=',', fmt='%s')\n",
    "np.savetxt(\"../results/validation_stats_Q17variable.csv\", [p for p in zip(val_losses, val_acc)], delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81452347",
   "metadata": {},
   "source": [
    "# Measure performance on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b098eb6e",
   "metadata": {},
   "source": [
    "The following three blocks should only be run during the first time of running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "324c556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the test images according to their resolutions and re-store them \n",
    "# RESOLUTIONS = [32,48,64]\n",
    "# TARGETS = [0,1,2,3,4,5,6,7,8,9]\n",
    "# ROOT = '../data' # .. to not have data folder within notebooks folder\n",
    "\n",
    "# for r in RESOLUTIONS:\n",
    "#     for t in TARGETS:\n",
    "#         os.makedirs(f'{ROOT}/{r}/test/{t}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bf8dbaa6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/64/test/mnist-varres/test\\\\0\\\\000000.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [90]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     im\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mROOT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/48/test/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m im\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mROOT\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/64/test/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtarget\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py:2317\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2315\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2316\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2317\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2319\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2320\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/64/test/mnist-varres/test\\\\0\\\\000000.png'"
     ]
    }
   ],
   "source": [
    "##for mac and linux\n",
    "# for file in list(glob.glob('../data/mnist-varres/test/*/*.png')):\n",
    "#     target = str.split(file, \"/\")[-2]\n",
    "#     filename = str.split(file, \"/\")[-1]\n",
    "#     im = Image.open(file)\n",
    "#     if im.size == (32, 32):\n",
    "#         im.save(f'{ROOT}/32/test/{target}/{filename}')\n",
    "#     elif im.size == (48, 48):\n",
    "#         im.save(f'{ROOT}/48/test/{target}/{filename}')\n",
    "#     elif im.size == (64,64):\n",
    "#         im.save(f'{ROOT}/64/test/{target}/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "caf049de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For windows:\n",
    "# for file in list(glob.glob('../data/mnist-varres/test/*/*.png')):\n",
    "#     target = str.split(file, \"\\\\\")[-2]\n",
    "#     filename = str.split(file, \"\\\\\")[-1]\n",
    "#     im = Image.open(file)\n",
    "#     if im.size == (32, 32):\n",
    "#         im.save(f'{ROOT}/32/test/{target}/{filename}')\n",
    "#     elif im.size == (48, 48):\n",
    "#         im.save(f'{ROOT}/48/test/{target}/{filename}')\n",
    "#     elif im.size == (64,64):\n",
    "#         im.save(f'{ROOT}/64/test/{target}/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "117c00ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader_test(test_set, BATCH_SIZE):\n",
    "    return torch.utils.data.DataLoader(test_set, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ca83f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "152e12f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_32 = torchvision.datasets.ImageFolder(root = '../data/mnist-varres/32/test',\n",
    "                                              transform=transform)\n",
    "test_48 = torchvision.datasets.ImageFolder(root = '../data/mnist-varres/48/test',\n",
    "                                              transform=transform)\n",
    "test_64 = torchvision.datasets.ImageFolder(root = '../data/mnist-varres/64/test',\n",
    "                                              transform=transform)\n",
    "\n",
    "test_loader_32 = get_dataloader(test_32, BATCH_SIZE)\n",
    "test_loader_48 = get_dataloader(test_48, BATCH_SIZE)\n",
    "test_loader_64 = get_dataloader(test_64, BATCH_SIZE)\n",
    "\n",
    "test_loaders = {'32': test_loader_32,\n",
    "                      '48': test_loader_48,\n",
    "                      '64': test_loader_64\n",
    "                     }\n",
    "\n",
    "test_size = {'32': len(test_32),\n",
    "                   '48': len(test_48),\n",
    "                   '64': len(test_64)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "68ff8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = [] \n",
    "test_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a6cbdc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_set_performance(test_loader, TEST_SIZE):\n",
    "\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    \n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        test_loss /= TEST_SIZE\n",
    "        test_losses.append(test_loss)\n",
    "        test_acc.append(float(100. * correct / TEST_SIZE))\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, TEST_SIZE,\n",
    "            100. * correct / TEST_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "92abac58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tRESOLUTION: 32\n",
      "\n",
      "Test set: Avg. loss: 0.1568, Accuracy: 3107/3269 (95%)\n",
      "\n",
      "\tRESOLUTION: 48\n",
      "\n",
      "Test set: Avg. loss: 0.1499, Accuracy: 3225/3381 (95%)\n",
      "\n",
      "\tRESOLUTION: 64\n",
      "\n",
      "Test set: Avg. loss: 0.1512, Accuracy: 3184/3350 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in test_loaders.keys():\n",
    "    print(f'\\tRESOLUTION: {r}')\n",
    "    test_set_performance(test_loaders[r], test_size[r])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "029ff5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'32': 3269, '48': 3381, '64': 3350}\n",
      "Final Test Accuracy =  95.16000006637573 %\n",
      "Final Avg. Loss =  0.15257839945480228\n"
     ]
    }
   ],
   "source": [
    "# calculate a weighted average of accuracy and avgloss\n",
    "final_acc = 0\n",
    "final_avgloss = 0\n",
    "\n",
    "for i, r in enumerate(test_loaders.keys()): \n",
    "    final_acc += test_acc[i] * test_size[r]\n",
    "    final_avgloss += test_losses[i] * test_size[r]\n",
    "final_acc /= sum([test_size[r] for r in test_loaders.keys()])\n",
    "final_avgloss /= sum([test_size[r] for r in test_loaders.keys()])\n",
    "\n",
    "print(test_size)\n",
    "print('Final Test Accuracy = ', final_acc, '%')\n",
    "print('Final Avg. Loss = ', final_avgloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f1643e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store values\n",
    "np.savetxt(\"../results/test_stats_Q17variable.csv\", [p for p in zip(test_losses, test_acc)], delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43700f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
