{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4736aca",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "\n",
    "Use the dataloaders to load both the train and the test set into large tensors:\n",
    "one for the instances, one for the labels. Split the training data into 50 000 training instances\n",
    "and 10 000 validation instances. Then write a training loop that loops over batches of 16\n",
    "instances at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b210f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import *\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f14b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 50000\n",
    "VALIDATION_SIZE = 10000\n",
    "ROOT = '../data' # .. to not have data folder within notebooks folder\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f905e766",
   "metadata": {},
   "source": [
    "### Data transformer\n",
    "\n",
    "See on PyTorch discussion forum [here](https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/2) on choice for 0.137 (mean) and 0.3081 (std.) for normalization. Official PyTorch example code for MNIST also uses these parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9197c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad97e759",
   "metadata": {},
   "source": [
    "### Training / validation data\n",
    "\n",
    "(Note: Using ```.dataset``` on **train_set** or **validation_set** will return the original 60000 instances, instead use the specified dataloaders further below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a232d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(root = ROOT,\n",
    "                                 train = True,\n",
    "                                 transform = transform,\n",
    "                                 download = True)\n",
    "train_set, validation_set = torch.utils.data.random_split(dataset, [TRAIN_SIZE, VALIDATION_SIZE])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           num_workers = 2)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set,\n",
    "                                                batch_size = BATCH_SIZE,\n",
    "                                                shuffle = True,\n",
    "                                                num_workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c22438",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae65ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = dataset = torchvision.datasets.MNIST(root = ROOT,\n",
    "                                 train = False,\n",
    "                                 transform = transform,\n",
    "                                 download = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          shuffle = True,\n",
    "                                          num_workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f548c3b",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "(Note: Training loop uses the dataloader **train_loader** and extracts _instances_ and _labels_. _Instances_ is shaped (batch_size,1,28,28), as is required for further operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5bbdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(EPOCHS):\n",
    "    print(f'# batches ({TRAIN_SIZE}/{BATCH_SIZE}): {TRAIN_SIZE // BATCH_SIZE}')\n",
    "    for batch_i, batch_data in enumerate(train_loader, 0):\n",
    "        #if batch_i >= 10: break (THIS ONE-LINER CAN BE USED TO CONTROL enumerate FOR BEBUGGING)\n",
    "        instances, labels = batch_data\n",
    "        \n",
    "        # (...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
